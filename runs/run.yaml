# settings.yaml file
# This file contains all settings for a model to run.

# Model Name
model_name: "rn18_pere_no_avg_pool_multi"    # String
root_dir_models: models         # string

##### Paths to data
lenses_path   : "data/training/lenses/"
negatives_path: "data/training/negatives/"
sources_path  : "data/training/sources/"

# Data type of images in the numpy array
data_type: "np.float32"

# Image dimensionality
img_width: 101
img_height: 101
img_channels: 1

# Whether to normalize (normalize per data array and not per image) the data during the image loading process.
normalize: "per_image"        #options = {"None", "per_image", "per_array", "adapt_hist_eq"}

# Determines the splitting point of the data. Splitting percentage between test and train data.
test_fraction: 0.2             # 0.2 means that 20% of the data will be reserved for test data.

# Alpha scaling, randomly drawn from this uniform distribution. Because the lensing features usually are of a lower luminosity than the LRG. Source scaling factor.
mock_lens_alpha_scaling_min: 0.02     #float
mock_lens_alpha_scaling_max: 0.30     #float

# Whether you want to see plots and extra print output
verbatim: False

# Augmenation Parameters:
aug_zoom_range_min: 1.0             #float# This range will be sampled from uniformly.
aug_zoom_range_max: 1.05            #float# This range will be sampled from uniformly.
aug_num_pixels_shift_allowed: 4     #int# In Pixels
aug_rotation_range    : 360         #int# In Degrees
aug_do_horizontal_flip: True        #boolean# 50% of the time do a horizontal flip)  
aug_default_fill_mode : 'nearest'   #string# Interpolation method, for data augmentation.

# Network Paramters
net_name         : "resnet18"        #string# Determines which model will be loaded: options={"resnet18"}
net_learning_rate: 0.0001            #float#
net_model_metrics: "binary_accuracy" #string#
net_num_outputs  : 1                 #int# How many output neurons does the network need?
net_epochs       : 1                 #int# How many epochs are done. Set to 1, because we generate infinite data. Therefore you should look at the parameter: num_chunks.
net_batch_size   : 16                #int#

# Loading the input data
fraction_to_load_lenses   : 0.5     #float# range = [0,1]
fraction_to_load_negatives: 0.5     #float# range = [0,1]
fraction_to_load_sources  : 0.1     #float# range = [0,1]

# Chunk Parameters
num_chunks: 6000                       #int # Number of chunks to be generated 
chunksize : 512                        #int # The number of images that will fit into one chunk

# Storing results parameters.
chunk_plot_interval: 10               #int # Determines at which training interval a plot of the loss and binary accuracy is generated and stored to a file.
chunk_save_interval: 50               #int # After this amount of chunks the model will be saved.

# Validation Params
# validation_steps: 8                # int # Amount of Validation steps to be performed during training of the model.
validation_chunksize: 512

## EXPERIMENT PARAMETERS
use_avg_pooling_2D: True            #boolean, # Whether the resnet contains GLOBAL AVG POOLING